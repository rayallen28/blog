# 使用卷积神经网络实现手写体数字识别
数据集：MNIST<br>
深度学习框架：PaddlePaddle（百度飞桨）<p>
卷积神经网络（CNN）构建过程：<br>
依次为：<br>
原始图像输入（Tensor）<br>
↓<br>
卷积运算（Conv）<br>
↓<br>
稀疏化（ReLU）<br>
↓<br>
池化<br>
↓<br>
全连接<br>
↓<br>
投票（概率输出）<p>
依赖包导入：<br>
```python
import numpy as np
import matplotlib.pyplot as plt
import paddle
from paddle.nn import Linear
import paddle.nn.functional as F
from paddle.vision.datasets import MNIST
```
模型定义：<br>
```python
# CNN网络定义
class MNISTNet(paddle.nn.Layer):
    def __init__(self):
        super(MNISTNet, self).__init__()
        # 卷积层定义
        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)
        # 池化层定义
        self.pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.conv2 = paddle.nn.Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)
        self.pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.fc = Linear(in_features=980, out_features=10)
        
    def forward(self, inputs, label=None, check_shape=False, check_content=False):
        outputs_conv1 = self.conv1(inputs)
        outputs_conv1_relu = F.relu(outputs_conv1)
        outputs_pool1 = self.pool1(outputs_conv1_relu)
        outputs_conv2 = self.conv2(outputs_pool1)
        outputs_conv2_relu = F.relu(outputs_conv2)
        outputs_pool2 = self.pool2(outputs_conv2_relu)
        outputs_pool2 = paddle.reshape(outputs_pool2, [outputs_pool2.shape[0], -1])
        outputs_fc = self.fc(outputs_pool2)
        
        if check_shape:
            print('网络超参数：')
            print(f'conv1-- kernel_size:{self.conv1.weight.shape}, padding:{self.conv1._padding}, stride:{self.conv1._stride}')
            print(f'conv2-- kernel_size:{self.conv2.weight.shape}, padding:{self.conv2._padding}, stride:{self.conv2._stride}')
            print(f'fc-- weight_size:{self.fc.weight.shape}, bias_size:{self.fc.bias.shape}')
            print('网络各层形状：')
            print(f'outputs_conv1:{outputs_conv1.shape}')
            print(f'outputs_conv1_relu:{outputs_conv1_relu.shape}')
            print(f'outputs_pool1:{outputs_pool1.shape}')
            print(f'outputs_conv2:{outputs_conv2.shape}')
            print(f'outputs_conv2_relu:{outputs_conv2_relu.shape}')
            print(f'outputs_pool2:{outputs_pool2.shape}')
            print(f'outputs_fc:{outputs_fc.shape}')
        if check_content:
            print('卷积核信息：')
            print(f'conv1 params-- kernel weights:{self.conv1.weight[0][0]}')
            print(f'conv2 params-- kernel weights:{self.conv2.weight[0][0]}')
            idx1 = np.random.randint(0, outputs_conv1.shape[1])
            idx2 = np.random.randint(0, outputs_conv2.shape[1])
            print(f'conv1的第{idx1}个通道的卷积结果：{outputs_conv1[0][idx1]}')
            print(f'conv2的第{idx2}个通道的卷积结果：{outputs_conv2[0][idx2]}')
            print(f'全连接层结果：{outputs_fc[0]}')
        if label is not None:
            acc = paddle.metric.accuracy(input=F.softmax(outputs_fc), label=label)
            return outputs_fc, acc
        else:
            return outputs_fc
  ```
  加载数据：<br>
  ```python
  def split_set(mnist):
    imgs = []
    labels = []
    for img in mnist.images:
        imgs.append(img)
    for label in mnist.labels:
        labels.append(label[0])
    return imgs, labels
  ```
  ```python
  # 训练数据加载
def load_data_opt(mode='train'):
    # 下载数据集
    train_set = MNIST(mode='train')
    test_set = MNIST(mode='test')
    # 图像宽高
    IMG_ROWS = 28
    IMG_COLS = 28
    if mode == 'train':
        imgs, labels = split_set(train_set)
    elif mode == 'test':
        imgs, labels = split_set(test_set)
    imgs_length = len(imgs)
    index_list = list(range(imgs_length))
    BATCHSIZE = 100
    # 数据投喂
    def data_generator():
        if mode == 'train':
            random.shuffle(index_list)
        imgs_list = []
        labels_list = []
        for i in index_list:
            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')
            label = np.reshape(labels[i], [1]).astype('int64')
            imgs_list.append(img)
            labels_list.append(label)
            if len(imgs_list) == BATCHSIZE:
                yield np.array(imgs_list), np.array(labels_list)
                imgs_list = []
                labels_list = []
        if len(imgs_list) > 0:
            yield np.array(imgs_list), np.array(labels_list)
    return data_generator
train_loader = load_data_opt('train')
  ```
  记录日志：<br>
  ```python
  log_writer = LogWriter(logdir='./log')
  ```
  模型训练：
  ```python
  # 模型训练
def train(model):
    model.train()
    # 学习率优化策略：动量 + 自适应
    opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())
    # 训练轮次
    EPOCH_NUM = 10
    iter_ = 0
    for epoch_id in range(EPOCH_NUM):
        for batch_id, data in enumerate(train_loader()):
            images, labels = data
            images = paddle.to_tensor(images)
            labels = paddle.to_tensor(labels)
            predicts, acc = model(images, labels, check_shape=False, check_content=False)
            # 损失函数定义：交叉熵
            loss = F.cross_entropy(predicts, labels)
            avg_loss = paddle.mean(loss)
            if batch_id % 100 == 0:
                print(f'轮次：{epoch_id}, 批次：{batch_id}, 损失值：{avg_loss.numpy()}, 精度：{acc.numpy()}')
                log_writer.add_scalar(tag='acc', step=iter_, value=acc.numpy())
                log_writer.add_scalar(tag='loss', step=iter_, value=avg_loss.numpy())
                iter_ = iter_ + 100
            # 反向传播梯度
            avg_loss.backward()
            opt.step()
            opt.clear_grad()
    # 模型存储
    paddle.save(model.state_dict(), 'mnist.pdparams')
model = MNISTNet()
train(model)
  ```
  训练输出：
  ```
  轮次：0, 批次：0, 损失值：[59.658813], 精度：[0.05]
轮次：0, 批次：100, 损失值：[2.0663056], 精度：[0.41]
轮次：0, 批次：200, 损失值：[1.209992], 精度：[0.65]
轮次：0, 批次：300, 损失值：[1.3459244], 精度：[0.61]
轮次：0, 批次：400, 损失值：[0.8700974], 精度：[0.73]
轮次：0, 批次：500, 损失值：[0.776693], 精度：[0.78]
轮次：1, 批次：0, 损失值：[0.7423259], 精度：[0.79]
轮次：1, 批次：100, 损失值：[0.97291267], 精度：[0.8]
轮次：1, 批次：200, 损失值：[0.76418173], 精度：[0.78]
轮次：1, 批次：300, 损失值：[0.40171048], 精度：[0.88]
轮次：1, 批次：400, 损失值：[0.5925873], 精度：[0.85]
轮次：1, 批次：500, 损失值：[0.5761037], 精度：[0.88]
轮次：2, 批次：0, 损失值：[0.4198603], 精度：[0.83]
轮次：2, 批次：100, 损失值：[0.49959907], 精度：[0.87]
轮次：2, 批次：200, 损失值：[0.7289031], 精度：[0.86]
轮次：2, 批次：300, 损失值：[0.48463413], 精度：[0.86]
轮次：2, 批次：400, 损失值：[0.25641713], 精度：[0.91]
轮次：2, 批次：500, 损失值：[0.28793195], 精度：[0.92]
轮次：3, 批次：0, 损失值：[0.23979221], 精度：[0.94]
轮次：3, 批次：100, 损失值：[0.2286962], 精度：[0.91]
轮次：3, 批次：200, 损失值：[0.4566882], 精度：[0.88]
轮次：3, 批次：300, 损失值：[0.3541779], 精度：[0.89]
轮次：3, 批次：400, 损失值：[0.34544528], 精度：[0.93]
轮次：3, 批次：500, 损失值：[0.33276725], 精度：[0.87]
轮次：4, 批次：0, 损失值：[0.34861866], 精度：[0.91]
轮次：4, 批次：100, 损失值：[0.29696223], 精度：[0.89]
轮次：4, 批次：200, 损失值：[0.23014861], 精度：[0.94]
轮次：4, 批次：300, 损失值：[0.478111], 精度：[0.88]
轮次：4, 批次：400, 损失值：[0.09851397], 精度：[0.95]
轮次：4, 批次：500, 损失值：[0.14117703], 精度：[0.96]
轮次：5, 批次：0, 损失值：[0.14000374], 精度：[0.94]
轮次：5, 批次：100, 损失值：[0.26302445], 精度：[0.92]
轮次：5, 批次：200, 损失值：[0.17180663], 精度：[0.96]
轮次：5, 批次：300, 损失值：[0.22057934], 精度：[0.93]
轮次：5, 批次：400, 损失值：[0.2095174], 精度：[0.95]
轮次：5, 批次：500, 损失值：[0.26001075], 精度：[0.93]
轮次：6, 批次：0, 损失值：[0.16936406], 精度：[0.96]
轮次：6, 批次：100, 损失值：[0.04402203], 精度：[0.98]
轮次：6, 批次：200, 损失值：[0.1921559], 精度：[0.94]
轮次：6, 批次：300, 损失值：[0.1275934], 精度：[0.95]
轮次：6, 批次：400, 损失值：[0.16987258], 精度：[0.96]
轮次：6, 批次：500, 损失值：[0.06287776], 精度：[0.98]
轮次：7, 批次：0, 损失值：[0.19804487], 精度：[0.94]
轮次：7, 批次：100, 损失值：[0.14448768], 精度：[0.97]
轮次：7, 批次：200, 损失值：[0.22600536], 精度：[0.96]
轮次：7, 批次：300, 损失值：[0.1757651], 精度：[0.94]
轮次：7, 批次：400, 损失值：[0.02632347], 精度：[0.99]
轮次：7, 批次：500, 损失值：[0.17805637], 精度：[0.95]
轮次：8, 批次：0, 损失值：[0.06644913], 精度：[0.96]
轮次：8, 批次：100, 损失值：[0.18608405], 精度：[0.96]
轮次：8, 批次：200, 损失值：[0.18601204], 精度：[0.92]
轮次：8, 批次：300, 损失值：[0.07111521], 精度：[0.98]
轮次：8, 批次：400, 损失值：[0.112441], 精度：[0.95]
轮次：8, 批次：500, 损失值：[0.19614512], 精度：[0.93]
轮次：9, 批次：0, 损失值：[0.18075284], 精度：[0.95]
轮次：9, 批次：100, 损失值：[0.02902464], 精度：[1.]
轮次：9, 批次：200, 损失值：[0.07047966], 精度：[0.96]
轮次：9, 批次：300, 损失值：[0.3297554], 精度：[0.91]
轮次：9, 批次：400, 损失值：[0.41000134], 精度：[0.91]
轮次：9, 批次：500, 损失值：[0.16342348], 精度：[0.96]
  ```
  验证模型：
  ```python
  # 测试模型
def test_model(model):
    param_dict = paddle.load('mnist.pdparams')
    model.load_dict(param_dict)
    model.eval()
    eval_loader = load_data_opt(mode='test')
    acc_set = []
    avg_loss_set = []
    for batch_id, data in enumerate(eval_loader()):
        images, labels = data
        images = paddle.to_tensor(images)
        labels = paddle.to_tensor(labels)
        predicts, acc = model(images, labels)
        loss = F.cross_entropy(input=predicts, label=labels)
        avg_loss = paddle.mean(loss)
        acc_set.append(float(acc.numpy()))
        avg_loss_set.append(float(avg_loss.numpy()))
    acc_val_mean = np.array(acc_set).mean()
    avg_loss_val_mean = np.array(avg_loss_set).mean()
    print(f'损失值：{avg_loss_val_mean}, 精度：{acc_val_mean}')
model = MNISTNet()
test_model(model)
  ```
  验证结果：
  ```
  损失值：0.22378026496618986, 精度：0.9478000044822693
  ```
  单词测试：
  ```python
  img = ds.images[84]
img_for_show = img.copy()
img = np.reshape(img, [1, 1, 28, 28]).astype('float32')
img = paddle.to_tensor(img)
model_dict = paddle.load('mnist.pdparams')
model.load_dict(model_dict)
model.eval()
result = model(img)
print('本次预测的数字是：', np.argsort(result.numpy())[0][-1])
plt.imshow(img_for_show.reshape(28, 28))
  ```
  预测结果：<br>
  
