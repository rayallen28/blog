# 企查查爬虫
```python
import sys
import os
import numpy as np
import pandas as pd
import requests
from urllib import parse
from bs4 import BeautifulSoup
import time
```
```python
cnt = 1
for v in cus.CHINESE_NAME.values:
    print(str(cnt) + v)
    cnt = cnt + 1
    if os.path.exists(v+'.txt') == True:
        continue;
    
    url = 'https://www.qcc.com/web/search?key={}'.format(parse.quote(v))
    path = url[19:]
    header = {'authority':'www.qcc.com',
                'method':'GET',
                'path':path,
                'scheme':'https',
                'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
                'accept-encoding':'gzip, deflate, br',
                'accept-language':'zh-CN,zh;q=0.9',
                'cache-control':'max-age=0',
                'cookie':'zg_did=%7B%22did%22%3A%20%2217278feae364ed-0c3813cbed3065-58143518-1fa400-17278feae37424%22%7D; _uab_collina=159116785725188946870574; Hm_lvt_78f134d5a9ac3f92524914d0247e70cb=1597649253,1597809164,1597887144,1598410596; UM_distinctid=176f4509cfb0-02c349d9ab427-3a3d530a-1fa400-176f4509cfc49; QCCSESSID=gur3ivr704oalb7730nfv6jjp6; hasShow=1; acw_tc=78ddc8a516112112518533871eae12c334d314c14743d95fe04635e8b9; CNZZDATA1254842228=37201017-1591164370-https%253A%252F%252Fsp0.baidu.com%252F%7C1611207290; zg_de1d1a35bfa24ce29bbf2c7eb17e6c4f=%7B%22sid%22%3A%201611211254443%2C%22updated%22%3A%201611212632940%2C%22info%22%3A%201611194422978%2C%22superProperty%22%3A%20%22%7B%5C%22%E5%BA%94%E7%94%A8%E5%90%8D%E7%A7%B0%5C%22%3A%20%5C%22%E4%BC%81%E6%9F%A5%E6%9F%A5%E7%BD%91%E7%AB%99%5C%22%7D%22%2C%22platform%22%3A%20%22%7B%7D%22%2C%22utm%22%3A%20%22%7B%7D%22%2C%22referrerDomain%22%3A%20%22%22%2C%22zs%22%3A%200%2C%22sc%22%3A%200%2C%22cuid%22%3A%20%22undefined%22%7D',
                'sec-ch-ua':'"Google Chrome";v="87", " Not;A Brand";v="99", "Chromium";v="87"',
                'sec-ch-ua-mobile':'?0',
                'sec-fetch-dest':'document',
                'sec-fetch-mode':'navigate',
                'sec-fetch-site':'none',
                'sec-fetch-user':'?1',
                'upgrade-insecure-requests':'1',
                'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'}
    r = requests.get(url, headers=header)
    soup = BeautifulSoup(r.content, 'html.parser')
    f = open(v + '.txt','w', encoding='utf-8')
    f.write(soup.text)
    f.close()
    time.sleep(2)
```
cus.CHINESE_NAME，cus存储企业信息，CHINESE_NAME为企业的中文名称。

将爬虫结果存储在一个文本文档中，以企业名称命名。

【声明】本代码纯技术研究，不可用于违法相关法律法规的用途。
